{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qu'est ce que le boosting ?**\n",
    "\n",
    "C'est une méthode d\"ensemble qui vise à créer un modèle fort à partir de plusieurs modèles plus faible. Concrètement, cela combine les prédictions de plusieurs modèles. Ces modèles sont de préférences simples et faibles. Dans le but d'améliorer la robustesse et la précision du modèle final.\n",
    "\n",
    "**Comment cela fonctionne ?**\n",
    "\n",
    "Contrairement au bagging, le boosting va se construire de manière itérative, séquentielle. En fait, chaque modèle va essayer de corriger les erreurs de modèle n-1.\n",
    "\n",
    "A chaque itération, le boosting permet d'augmenter le poids des observations mal classées pour que le modèle suivant se concentre sur les cas difficiles. On peut voir cela comme une analyse qui augmente sa finesse au fur et à mesure, comme dans un entonnoir.\n",
    "\n",
    "Pour cela, on va utiliser des modèles faibles (\"Stumps\"). Concrètement, l'idée est de corriger progressivement au lieu d'utiliser un modèle de machine de guerre dès le départ.\n",
    "\n",
    "**Il existe deux types de boosting**\n",
    "\n",
    "- *AdaBoost(Adaptive Boosting)* \n",
    "- *Gradient Boosting*\n",
    "\n",
    "Dans ce notebook nous allons nous intéresser au Gradient Boosting. Il permet d'améliorer les prédictions en utilisant la descente de gradient pour minimiser les erreurs.\n",
    "Dans une autre partie du cours, nous verrons que nous pouvons utiliser *XGBoost, LightGBM et CatBoost* qui sont des variations avancées du gradient boosting.\n",
    "\n",
    "**Quels sont les avantages du boosting ?**\n",
    "\n",
    "- *Une précision plus grande et une bonne performance , autant sur des problèmes de classification que de régression.*\n",
    "\n",
    "- *Il corrige les erreurs et réduit la variance , cela réduit le biais gràce à la combinaison de plusieurs modèles*\n",
    "\n",
    "**Quels sont les limites ?**\n",
    "\n",
    "- *Le boosting peut provoqué un over-fitting s'il n'est pas bien régulé.*\n",
    "- *Il est sensible aux outliers*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
