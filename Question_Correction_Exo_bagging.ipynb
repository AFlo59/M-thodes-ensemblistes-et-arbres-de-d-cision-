{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercices sur le Bagging et le Pasting :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 : Bagging vs. Pasting\n",
    "\n",
    "Expliquez brièvement la différence entre le Bagging et le Pasting. Quels sont les avantages de chaque méthode et dans quel contexte pourriez-vous privilégier l'une par rapport à l'autre ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 : Rôle de l'échantillonnage Bootstrap\n",
    "\n",
    "Dans le contexte du Bagging, expliquez le rôle de l'échantillonnage bootstrap. En quoi cela contribue-t-il à la diversité des modèles dans l'ensemble ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 : Impact du Bootstrap sur la Corrélation\n",
    "\n",
    "Comment l'échantillonnage bootstrap dans le Bagging affecte-t-il la corrélation entre les modèles de l'ensemble ? En quoi cela contribue-t-il à améliorer la performance globale ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 : Bagging avec Différents Modèles de Base\n",
    "\n",
    "Le Bagging peut être utilisé avec différents types de modèles de base. Citez au moins deux autres modèles de base (autres que les arbres de décision) qui pourraient être utilisés avec le Bagging, et expliquez brièvement dans quels cas cela pourrait être bénéfique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 : Critères de Performance\n",
    "\n",
    "Lors de l'évaluation de la performance d'un modèle Bagging ou Pasting, quels critères de performance pourriez-vous utiliser ? Expliquez pourquoi ces critères sont pertinents dans ce contexte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 : Bagging vs. Pasting\n",
    "\n",
    "Le Bagging et le Pasting sont des techniques d'ensemble où plusieurs modèles sont entraînés sur des sous-ensembles différents des données. La différence principale réside dans l'échantillonnage : le Bagging utilise un échantillonnage avec remplacement (bootstrap), tandis que le Pasting utilise un échantillonnage sans remplacement. Les avantages du Bagging incluent une meilleure généralisation et une réduction de la variance, tandis que le Pasting peut être moins sensible aux outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 : Rôle de l'échantillonnage Bootstrap\n",
    "\n",
    "L'échantillonnage bootstrap dans le Bagging permet de créer plusieurs ensembles d'entraînement à partir d'un seul ensemble de données en tirant aléatoirement des échantillons avec remplacement. Cela introduit de la diversité dans les modèles de l'ensemble, car chaque modèle voit une version légèrement différente des données, ce qui réduit la corrélation entre les modèles et améliore la robustesse du modèle global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 : Impact du Bootstrap sur la Corrélation\n",
    "\n",
    "L'échantillonnage bootstrap réduit la corrélation entre les modèles du Bagging, car chaque modèle voit un échantillon légèrement différent lors de son entraînement. Cela aide à éviter le surajustement, car les modèles sont moins susceptibles de reproduire les mêmes erreurs sur les mêmes échantillons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 : Bagging avec Différents Modèles de Base\n",
    "\n",
    "Le Bagging n'est pas limité aux arbres de décision comme modèles de base. D'autres modèles tels que les régressions logistiques, les k-plus proches voisins (KNN) ou les machines à vecteurs de support (SVM) peuvent également être utilisés. L'utilisation de modèles de base différents peut être bénéfique lorsque ces modèles apportent des perspectives différentes sur le problème, contribuant ainsi à la diversité de l'ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 : Critères de Performance\n",
    "\n",
    "Les critères de performance pour évaluer un modèle Bagging peuvent inclure la précision, le rappel, la F1-score, ou toute autre mesure appropriée à la nature du problème. En général, les critères de performance devraient refléter la capacité du modèle à bien généraliser sur de nouvelles données, en évitant le surajustement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice d'Implémentation :\n",
    "\n",
    "#### Exercice : Bagging avec des Arbres de Décision\n",
    "\n",
    "Utilisez scikit-learn pour implémenter un modèle Bagging avec des arbres de décision comme modèles de base. Suivez ces étapes :\n",
    "\n",
    "    Chargez un ensemble de données approprié (vous pouvez utiliser une base de données intégrée à scikit-learn).\n",
    "    Divisez le jeu de données en ensembles d'entraînement et de test.\n",
    "    Créez un modèle Bagging avec un arbre de décision comme modèle de base.\n",
    "    Ajustez le modèle sur l'ensemble d'entraînement.\n",
    "    Évaluez la performance du modèle sur l'ensemble de test en utilisant un critère approprié (par exemple, précision, rappel, F1-score).\n",
    "\n",
    "Assurez-vous de commenter votre code pour expliquer chaque étape de l'implémentation. Vous pouvez également expérimenter avec différents hyperparamètres du modèle Bagging pour observer leur impact sur la performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargez un ensemble de données approprié"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger un ensemble de données (par exemple, Iris)\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisez le jeu de données en ensembles d'entraînement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser le jeu de données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créez un modèle Bagging avec un arbre de décision comme modèle de base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle Bagging avec un arbre de décision comme modèle de base\n",
    "base_model = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "model_bagging = BaggingClassifier(base_model, n_estimators=50, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustez le modèle sur l'ensemble d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42),\n",
       "                  n_estimators=50, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42),\n",
       "                  n_estimators=50, random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42),\n",
       "                  n_estimators=50, random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajuster le modèle sur l'ensemble d'entraînement\n",
    "model_bagging.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Évaluez la performance du modèle sur l'ensemble de test en utilisant un critère approprié"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Bagging: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Évaluer la performance sur l'ensemble de test\n",
    "predictions = model_bagging.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy with Bagging: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculer la précision\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m precision \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_score\u001b[49m(y_test, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# pour le multiclasse\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision with Bagging: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'precision_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculer la précision\n",
    "precision = precision_score(y_test, predictions, average='weighted')  # pour le multiclasse\n",
    "print(f\"Precision with Bagging: {precision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le score F1\n",
    "f1 = f1_score(y_test, predictions, average='weighted')  # pour le multiclasse\n",
    "print(f\"F1 Score with Bagging: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
